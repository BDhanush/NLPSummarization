{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip3 install networkx\n",
        "!pip3 install -U nltk\n",
        "!pip3 install rouge\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6ySd84SmYjp",
        "outputId": "e6b3bb06-325f-4a52-c441-547744534791"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from rouge import Rouge\n",
        "import networkx as nx\n",
        "import sys\n",
        "import nltk\n",
        "sys.setrecursionlimit(10**6)"
      ],
      "metadata": {
        "id": "dsG2ZClImSih"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKAaQpyWJoz9",
        "outputId": "397619d7-a292-42bc-dc7f-54d2c9b51298"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Read the dataset from CSV\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/NLP/data/data3.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/NLP/data/data7.csv')\n",
        "\n",
        "# Concatenate the dataframes vertically\n",
        "data = pd.concat([df1, df2], axis=0)\n",
        "\n",
        "data.dropna(subset=['title', 'abstract'], inplace=True)\n",
        "# Reset the index of the combined dataframe\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "data = data.head(2000)\n",
        "# Preprocessing\n",
        "def preprocess_text(text):\n",
        "    if isinstance(text, str):  # Check if the text is a valid string\n",
        "        sentences = sent_tokenize(text)\n",
        "        return sentences\n",
        "    return []\n",
        "\n",
        "data['preprocessed_abstract'] = data['abstract'].apply(preprocess_text)\n",
        "\n",
        "# Filter out empty or missing abstracts\n",
        "data = data[data['preprocessed_abstract'].apply(len) > 0]\n",
        "\n",
        "# Select a subset of data points\n",
        "\n",
        "\n",
        "# Sentence Similarity\n",
        "vectorizer = TfidfVectorizer()\n",
        "sentence_vectors = vectorizer.fit_transform(data['preprocessed_abstract'].apply(' '.join))\n",
        "similarity_matrix = cosine_similarity(sentence_vectors)\n",
        "\n",
        "# Graph Construction\n",
        "graph = nx.from_numpy_array(similarity_matrix)\n",
        "\n",
        "# Graph Ranking (PageRank)\n",
        "scores = nx.pagerank(graph)\n",
        "\n",
        "# Calculate sentence scores\n",
        "sentence_scores = {i: score for i, score in enumerate(scores)}\n",
        "\n",
        "# Set the ratio of sentences to include in the summary\n",
        "summary_ratio = 0.3  # Adjust as needed\n",
        "\n",
        "# Select Top Sentences based on scores\n",
        "num_sentences = int(len(data) * summary_ratio)\n",
        "top_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)[:num_sentences]\n",
        "summary = ' '.join([data['preprocessed_abstract'][i][0] for i in top_sentences])  # Use [0] to get the first sentence\n",
        "\n",
        "# Extract the corresponding titles for evaluation\n",
        "titles = [data['title'][i] for i in top_sentences]\n",
        "\n",
        "# Compute ROUGE score\n",
        "rouge = Rouge()\n",
        "rouge_scores = rouge.get_scores(summary, ' '.join(titles))\n",
        "\n",
        "# Extract the ROUGE-1 F1 score for evaluation\n",
        "rouge_1_f1_score = rouge_scores[0]['rouge-1']['f']\n",
        "\n",
        "print(\"Generated Summary:\", summary)\n",
        "print(\"ROUGE-1 F1 Score:\", rouge_1_f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lnbo6vK630Rl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}